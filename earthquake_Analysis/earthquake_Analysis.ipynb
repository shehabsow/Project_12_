{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import streamlit as st\n",
    "## user_agent\n",
    "import user_agents\n",
    "# conda install -c conda-forge user-agents\n",
    "from geopy.distance import great_circle\n",
    "\n",
    "from ip2geotools.databases.noncommercial import DbIpCity as ip2geo\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"earthquake_1995-2023.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Understand Data\n",
    "\n",
    "* a) Understand Columns\n",
    "\n",
    "* b) Datatype check and Convert\n",
    "\n",
    "* c) .describe() -> to see all values\n",
    "\n",
    "* d) check unique values of categorical and their count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_time'] = pd.to_datetime(df['date_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = df.select_dtypes(include='O').columns\n",
    "\n",
    "for cat in categorical:\n",
    "    print(f\"{cat} column has number of uniques : {df[cat].nunique()}\")\n",
    "    print(f\"{cat} column has uniques : {df[cat].unique()}\")\n",
    "    print(f'\\n{\"-\"*50}\\n')\n",
    "    print(f\"{cat} column each unique repeated by:\")\n",
    "    print(df[cat].value_counts())\n",
    "    print(f'\\n{\"-\"*50}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = df.select_dtypes(exclude= 'object').columns\n",
    "\n",
    "for cat in numerical:\n",
    "    print(f\"{cat} column has number of uniques : {df[cat].nunique()}\")\n",
    "    print(f\"{cat} column has uniques : {df[cat].unique()}\")\n",
    "    print(f'\\n{\"-\"*50}\\n')\n",
    "    print(f\"{cat} column each unique repeated by:\")\n",
    "    print(df[cat].value_counts())\n",
    "    print(f'\\n{\"-\"*50}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Data Cleaning\n",
    "\n",
    "* NaNs check and Impute\n",
    "\n",
    "* Duplicate check and remove\n",
    "\n",
    "* Outliers check and handle\n",
    "\n",
    "* Data Inconsistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df['alert'] = imputer.fit_transform(df[['alert']])\n",
    "df.isnull().mean() * 100\n",
    "\n",
    "#px.histogram(df, x= 'alert')\n",
    "df['alert'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['location'] = imputer.fit_transform(df[['location']])\n",
    "df.drop(['country','continent'], axis=1, inplace=True)\n",
    "df.isnull().mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'] = df['date_time'].dt.year\n",
    "df['Month_Name'] = df['date_time'].dt.month_name()\n",
    "df['Week'] = df['date_time'].dt.isocalendar().week\n",
    "df['Day_Name'] = df['date_time'].dt.day_name()\n",
    "df['Hour'] = df['date_time'].dt.hour\n",
    "df['Hour'] = df['Hour'].astype(float)\n",
    "df.drop(['date_time'], axis=1, inplace=True)\n",
    "\n",
    "dff = df\n",
    "dff.info()\n",
    "dff.isnull().mean() * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def format_hours(row):\n",
    "    if row['Hour'] in range(0, 12):\n",
    "        return 'AM'\n",
    "    else:\n",
    "        return 'BM'\n",
    "    \n",
    "dff['Hour'] = pd.to_numeric(df['Hour'], errors='coerce')\n",
    "\n",
    "dff['AM_BM'] = df.apply(format_hours, axis=1)\n",
    "dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_tsunami(row):\n",
    "    if row['tsunami'] == 0 :\n",
    "        return 'residence'\n",
    "    else:\n",
    "        return 'oceanic'\n",
    "dff['tsunami'] = df.apply(format_tsunami, axis=1)\n",
    "\n",
    "dff "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 biggest number of sig and title location ?\n",
    "\n",
    "dff['sig'].max()\n",
    "dff.sort_values(by='sig', ascending=False)[['title', 'magnitude', 'location','sig']].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What the top 10 earthquakes by magnitude and signature in recent years and where were those earthquakes?\n",
    "dff['Year'].max()\n",
    "dff.sort_values(by='Year', ascending=False)[['title','sig','magnitude', 'location','Year']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is The most frequent and location of earthquakes \n",
    "dff.groupby(['title','location'])[['Year']].size().sort_values( ascending=False).reset_index().head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What  where tsunamis were recorded during each month, and how many tsunamis were recorded at each location?\n",
    "dff.groupby(['Month_Name','location','Year'])[['tsunami']].count().sort_values(by='tsunami', ascending=False).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Visuallization for categorical colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show count of all categorical features\n",
    "categorical = dff.select_dtypes(include='O').columns\n",
    "\n",
    "for col in categorical:\n",
    "    fig = px.bar(dff, x= col)\n",
    "    fig_1 = px.box(dff, x=col)\n",
    "    fig_1.show()\n",
    "    fig.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visuallization for numerical colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show distribution of all numerical features\n",
    "numerical = dff.select_dtypes(exclude= 'object').columns\n",
    "\n",
    "for col in numerical:\n",
    "    fig = px.histogram(dff, x= col)\n",
    "    fig_1 = px.box(dff, x=col)\n",
    "    fig_1.show()\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## The most common alert and its impact on the event? ! tsunami 0 == Residential locations & tsunami 1 == Surrounding locations\n",
    "\n",
    "figure = px.scatter(dff, x='alert' , y='sig',  color='tsunami',title='Relation Ship btn cdi  vs mmi')\n",
    "figure = figure.update_layout(width=600, height=450)\n",
    "figure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##  Which months witness the highest seismic activity during the year?\n",
    "mon_highest = dff.groupby('Month_Name')['Year'].count().sort_values( ascending=False).reset_index().head(10)\n",
    "px.pie(mon_highest, names='Month_Name', values='Year',color='Month_Name')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Is there a change in the intensity of earthquakes over time? Is there any effect of a tsunami\n",
    "df_time = df.groupby(['Year','tsunami'])['sig'].sum().reset_index().sort_values(by= 'sig')\n",
    "\n",
    "fig_1 = px.line(df_time, x= 'sig', y= ['Year'],  color= 'tsunami', title= 'Total earthquakes & tsunami over Time Period (1995-2023)')\n",
    "fig_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  What is the most media coverage of the event?\n",
    "occu_avg = dff.groupby(['net','tsunami'])['sig'].size().sort_values(ascending= False).reset_index()\n",
    "px.bar(occu_avg, x= 'net', y= 'sig',color='tsunami')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## What is the impact of the presence of stations inside residential areas?#\n",
    "impact = dff.groupby(['location','nst'])['sig'].size().sort_values(ascending= False).reset_index().head(500)\n",
    "\n",
    "px.bar(impact, x= 'location', y= 'sig',color='nst')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Average impact of algorithms on event importance\n",
    "algorithms = dff.groupby(['magtype','tsunami'])['sig'].mean().sort_values(ascending= False).reset_index()\n",
    "\n",
    "px.bar(algorithms, x= 'magtype', y= 'sig', color= 'tsunami' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## How many earthquakes have occurred in certain places and what is the magnitude of the earthquake’s intensity??\n",
    "earthquakes = dff.groupby(['location','magnitude'])['title'].count().sort_values(ascending= False).reset_index().head(100)\n",
    "px.bar(earthquakes, x= 'location', y= 'title', color= 'magnitude')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What is the alert rate affected by the event?\n",
    "affected = dff.groupby(['alert','mmi'])['sig'].count().sort_values(ascending= False).reset_index()\n",
    "\n",
    "px.bar(affected, x= 'alert', y= 'sig',color= 'mmi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The relationship between all the data\n",
    "px.imshow(dff.corr(), text_auto=True, width=1000, height=900)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stremlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.to_csv('cleaned_dff.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile earthquake_1995.py\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "dff = pd.read_csv('cleaned_dff.csv')\n",
    "mon_highest = dff.groupby('Month_Name')['Year'].count().sort_values( ascending=False).reset_index().head(10)\n",
    "df_time = dff.groupby(['Year','tsunami'])['sig'].sum().reset_index().sort_values(by= 'sig')\n",
    "occu_avg = dff.groupby(['net','tsunami'])['sig'].size().sort_values(ascending= False).reset_index()\n",
    "impact = dff.groupby(['location','nst'])['sig'].size().sort_values(ascending= False).reset_index().head(500)\n",
    "algorithms = dff.groupby(['magtype','tsunami'])['sig'].mean().sort_values(ascending= False).reset_index()\n",
    "earthquakes_avg = dff.groupby(['location','magnitude'])['title'].count().sort_values(ascending= False).reset_index().head(100)\n",
    "affected = dff.groupby(['alert','mmi'])['sig'].count().sort_values(ascending= False).reset_index()\n",
    "#earthquakes_avg = dff.groupby(['location','magnitude'])['alert'].count().sort_values(ascending= False).reset_index().head(100)\n",
    "\n",
    "\n",
    "\n",
    "st.title('earthquake from 1995 to 2023')\n",
    "\n",
    "page =  st.sidebar.radio('Select page', ['About','Univariate Analysis', 'Bivariate Analysis', 'Multivariate Analysis'])\n",
    "\n",
    "\n",
    "if page == 'About':\n",
    "    \n",
    "    def main():\n",
    "        \n",
    "        st.title('About Suberstore Project')\n",
    "        st.write(dff)\n",
    "        \n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        main()\n",
    "        \n",
    "if page == 'Univariate Analysis':\n",
    "\n",
    "    def main():\n",
    "    \n",
    "        # create tabs of numerical and categorical features\n",
    "        tab1, tab2 = st.tabs(['Numerical Features', 'Categorical Features'])\n",
    "        \n",
    "        # Numerical Features\n",
    "        num_cols = dff.select_dtypes(exclude= 'object').columns\n",
    "        \n",
    "        for col in num_cols:\n",
    "            tab1.plotly_chart(px.histogram(dff, x = col))\n",
    "            \n",
    "        # Categorical features\n",
    "        cat_cols = dff.select_dtypes(include= 'object').columns\n",
    "        \n",
    "        for col in cat_cols:\n",
    "            tab2.plotly_chart(px.histogram(dff, x = col))\n",
    "            \n",
    "            \n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        main()\n",
    "    \n",
    "elif page == 'Bivariate Analysis':\n",
    "    \n",
    "    def main():\n",
    "        \n",
    "        st.write('# Numerical features VS Target Variable')\n",
    "        \n",
    "        # Create selection box for features and plots\n",
    "        select_col = st.selectbox('Select Feature', ['magnitude', 'mmi', 'tsunami', 'sig', 'nst',\n",
    "         'latitude', 'longitude','Year'])\n",
    "        \n",
    "        select_plot = st.selectbox('Select Plot Type', ['Box plot', 'Violin Plot', 'Bar Chart Plot'])\n",
    "        \n",
    "        if select_plot == 'Box plot':\n",
    "            \n",
    "            st.plotly_chart(px.box(dff, x= 'title', y= select_col))\n",
    "            \n",
    "        elif select_plot == 'Violin Plot':\n",
    "            \n",
    "            st.plotly_chart(px.violin(dff, x= 'title', y= select_col))\n",
    "\n",
    "        else:\n",
    "            \n",
    "            st.plotly_chart(px.bar(dff, x= 'title', y= select_col))\n",
    "        \n",
    "    if __name__ == '__main__':\n",
    "\n",
    "        main()\n",
    "        \n",
    "else:\n",
    "    \n",
    "    def main():\n",
    "        \n",
    "        st.header('1- The most common alert and its impact on the event?') \n",
    "        \n",
    "        st.plotly_chart(px.scatter(dff, x='alert' , y='sig',  color='tsunami',title='Relation Ship btn cdi  vs mmi'))\n",
    "        \n",
    "        st.header('Which months witness the highest seismic activity during the year?')\n",
    "        \n",
    "        st.plotly_chart(px.pie(mon_highest, names='Month_Name', values='Year',color='Month_Name'))   \n",
    "        \n",
    "        st.header('Is there a change in the intensity of earthquakes over time? Is there any effect of a tsunami?')\n",
    "        \n",
    "        st.plotly_chart( px.line(df_time, x= 'sig', y= ['Year'],  color= 'tsunami', title= 'Total earthquakes & tsunami over Time Period (1995-2023)'))\n",
    "        \n",
    "        st.header(' What is the most media coverage of the event?')\n",
    "        \n",
    "        st.plotly_chart(px.bar(occu_avg, x= 'net', y= 'sig',color='tsunami'))\n",
    "        \n",
    "        st.header('What is the impact of the presence of stations inside residential areas?')\n",
    "        \n",
    "        st.plotly_chart(px.bar(impact, x= 'location', y= 'sig',color='nst'))\n",
    "        \n",
    "        st.header('Average impact of algorithms on event importance')\n",
    "        \n",
    "        st.plotly_chart(px.bar(algorithms, x= 'magtype', y= 'sig', color= 'tsunami' ))\n",
    "        \n",
    "        st.header('How many earthquakes have occurred in certain places and what is the magnitude of the earthquake’s intensity?')\n",
    "        \n",
    "        st.plotly_chart(px.bar(earthquakes_avg, x= 'location', y= 'title', color= 'magnitude'))\n",
    "        \n",
    "        st.header('What is the alert rate affected by the event?')\n",
    "        \n",
    "        st.plotly_chart(px.bar(affected, x= 'alert', y= 'sig',color= 'mmi'))\n",
    "        \n",
    "        #st.header('The relationship between all the data')\n",
    "        \n",
    "        #st.plotly_chart(px.bar(earthquakes, x= 'location', y= 'title', color= 'magnitude'))\n",
    "\n",
    "      \n",
    "    if __name__ == '__main__':\n",
    "        \n",
    "        main()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! streamlit run earthquake_1995.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import BinaryEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
